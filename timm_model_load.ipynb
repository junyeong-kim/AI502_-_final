{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junyeong/opt/anaconda3/envs/torch_mps/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm.models\n",
    "from torchsummary import summary as summary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [1, 384, 14, 14]         295,296\n",
      "          Identity-2              [1, 196, 384]               0\n",
      "        PatchEmbed-3              [1, 196, 384]               0\n",
      "           Dropout-4              [1, 197, 384]               0\n",
      "          Identity-5              [1, 197, 384]               0\n",
      "          Identity-6              [1, 197, 384]               0\n",
      "         LayerNorm-7              [1, 197, 384]             768\n",
      "            Linear-8             [1, 197, 1152]         443,520\n",
      "          Identity-9            [1, 6, 197, 64]               0\n",
      "         Identity-10            [1, 6, 197, 64]               0\n",
      "           Linear-11              [1, 197, 384]         147,840\n",
      "          Dropout-12              [1, 197, 384]               0\n",
      "        Attention-13              [1, 197, 384]               0\n",
      "         Identity-14              [1, 197, 384]               0\n",
      "         Identity-15              [1, 197, 384]               0\n",
      "        LayerNorm-16              [1, 197, 384]             768\n",
      "           Linear-17             [1, 197, 1536]         591,360\n",
      "             GELU-18             [1, 197, 1536]               0\n",
      "          Dropout-19             [1, 197, 1536]               0\n",
      "           Linear-20              [1, 197, 384]         590,208\n",
      "          Dropout-21              [1, 197, 384]               0\n",
      "              Mlp-22              [1, 197, 384]               0\n",
      "         Identity-23              [1, 197, 384]               0\n",
      "         Identity-24              [1, 197, 384]               0\n",
      "            Block-25              [1, 197, 384]               0\n",
      "        LayerNorm-26              [1, 197, 384]             768\n",
      "           Linear-27             [1, 197, 1152]         443,520\n",
      "         Identity-28            [1, 6, 197, 64]               0\n",
      "         Identity-29            [1, 6, 197, 64]               0\n",
      "           Linear-30              [1, 197, 384]         147,840\n",
      "          Dropout-31              [1, 197, 384]               0\n",
      "        Attention-32              [1, 197, 384]               0\n",
      "         Identity-33              [1, 197, 384]               0\n",
      "         Identity-34              [1, 197, 384]               0\n",
      "        LayerNorm-35              [1, 197, 384]             768\n",
      "           Linear-36             [1, 197, 1536]         591,360\n",
      "             GELU-37             [1, 197, 1536]               0\n",
      "          Dropout-38             [1, 197, 1536]               0\n",
      "           Linear-39              [1, 197, 384]         590,208\n",
      "          Dropout-40              [1, 197, 384]               0\n",
      "              Mlp-41              [1, 197, 384]               0\n",
      "         Identity-42              [1, 197, 384]               0\n",
      "         Identity-43              [1, 197, 384]               0\n",
      "            Block-44              [1, 197, 384]               0\n",
      "        LayerNorm-45              [1, 197, 384]             768\n",
      "           Linear-46             [1, 197, 1152]         443,520\n",
      "         Identity-47            [1, 6, 197, 64]               0\n",
      "         Identity-48            [1, 6, 197, 64]               0\n",
      "           Linear-49              [1, 197, 384]         147,840\n",
      "          Dropout-50              [1, 197, 384]               0\n",
      "        Attention-51              [1, 197, 384]               0\n",
      "         Identity-52              [1, 197, 384]               0\n",
      "         Identity-53              [1, 197, 384]               0\n",
      "        LayerNorm-54              [1, 197, 384]             768\n",
      "           Linear-55             [1, 197, 1536]         591,360\n",
      "             GELU-56             [1, 197, 1536]               0\n",
      "          Dropout-57             [1, 197, 1536]               0\n",
      "           Linear-58              [1, 197, 384]         590,208\n",
      "          Dropout-59              [1, 197, 384]               0\n",
      "              Mlp-60              [1, 197, 384]               0\n",
      "         Identity-61              [1, 197, 384]               0\n",
      "         Identity-62              [1, 197, 384]               0\n",
      "            Block-63              [1, 197, 384]               0\n",
      "        LayerNorm-64              [1, 197, 384]             768\n",
      "           Linear-65             [1, 197, 1152]         443,520\n",
      "         Identity-66            [1, 6, 197, 64]               0\n",
      "         Identity-67            [1, 6, 197, 64]               0\n",
      "           Linear-68              [1, 197, 384]         147,840\n",
      "          Dropout-69              [1, 197, 384]               0\n",
      "        Attention-70              [1, 197, 384]               0\n",
      "         Identity-71              [1, 197, 384]               0\n",
      "         Identity-72              [1, 197, 384]               0\n",
      "        LayerNorm-73              [1, 197, 384]             768\n",
      "           Linear-74             [1, 197, 1536]         591,360\n",
      "             GELU-75             [1, 197, 1536]               0\n",
      "          Dropout-76             [1, 197, 1536]               0\n",
      "           Linear-77              [1, 197, 384]         590,208\n",
      "          Dropout-78              [1, 197, 384]               0\n",
      "              Mlp-79              [1, 197, 384]               0\n",
      "         Identity-80              [1, 197, 384]               0\n",
      "         Identity-81              [1, 197, 384]               0\n",
      "            Block-82              [1, 197, 384]               0\n",
      "        LayerNorm-83              [1, 197, 384]             768\n",
      "           Linear-84             [1, 197, 1152]         443,520\n",
      "         Identity-85            [1, 6, 197, 64]               0\n",
      "         Identity-86            [1, 6, 197, 64]               0\n",
      "           Linear-87              [1, 197, 384]         147,840\n",
      "          Dropout-88              [1, 197, 384]               0\n",
      "        Attention-89              [1, 197, 384]               0\n",
      "         Identity-90              [1, 197, 384]               0\n",
      "         Identity-91              [1, 197, 384]               0\n",
      "        LayerNorm-92              [1, 197, 384]             768\n",
      "           Linear-93             [1, 197, 1536]         591,360\n",
      "             GELU-94             [1, 197, 1536]               0\n",
      "          Dropout-95             [1, 197, 1536]               0\n",
      "           Linear-96              [1, 197, 384]         590,208\n",
      "          Dropout-97              [1, 197, 384]               0\n",
      "              Mlp-98              [1, 197, 384]               0\n",
      "         Identity-99              [1, 197, 384]               0\n",
      "        Identity-100              [1, 197, 384]               0\n",
      "           Block-101              [1, 197, 384]               0\n",
      "       LayerNorm-102              [1, 197, 384]             768\n",
      "          Linear-103             [1, 197, 1152]         443,520\n",
      "        Identity-104            [1, 6, 197, 64]               0\n",
      "        Identity-105            [1, 6, 197, 64]               0\n",
      "          Linear-106              [1, 197, 384]         147,840\n",
      "         Dropout-107              [1, 197, 384]               0\n",
      "       Attention-108              [1, 197, 384]               0\n",
      "        Identity-109              [1, 197, 384]               0\n",
      "        Identity-110              [1, 197, 384]               0\n",
      "       LayerNorm-111              [1, 197, 384]             768\n",
      "          Linear-112             [1, 197, 1536]         591,360\n",
      "            GELU-113             [1, 197, 1536]               0\n",
      "         Dropout-114             [1, 197, 1536]               0\n",
      "          Linear-115              [1, 197, 384]         590,208\n",
      "         Dropout-116              [1, 197, 384]               0\n",
      "             Mlp-117              [1, 197, 384]               0\n",
      "        Identity-118              [1, 197, 384]               0\n",
      "        Identity-119              [1, 197, 384]               0\n",
      "           Block-120              [1, 197, 384]               0\n",
      "       LayerNorm-121              [1, 197, 384]             768\n",
      "          Linear-122             [1, 197, 1152]         443,520\n",
      "        Identity-123            [1, 6, 197, 64]               0\n",
      "        Identity-124            [1, 6, 197, 64]               0\n",
      "          Linear-125              [1, 197, 384]         147,840\n",
      "         Dropout-126              [1, 197, 384]               0\n",
      "       Attention-127              [1, 197, 384]               0\n",
      "        Identity-128              [1, 197, 384]               0\n",
      "        Identity-129              [1, 197, 384]               0\n",
      "       LayerNorm-130              [1, 197, 384]             768\n",
      "          Linear-131             [1, 197, 1536]         591,360\n",
      "            GELU-132             [1, 197, 1536]               0\n",
      "         Dropout-133             [1, 197, 1536]               0\n",
      "          Linear-134              [1, 197, 384]         590,208\n",
      "         Dropout-135              [1, 197, 384]               0\n",
      "             Mlp-136              [1, 197, 384]               0\n",
      "        Identity-137              [1, 197, 384]               0\n",
      "        Identity-138              [1, 197, 384]               0\n",
      "           Block-139              [1, 197, 384]               0\n",
      "       LayerNorm-140              [1, 197, 384]             768\n",
      "          Linear-141             [1, 197, 1152]         443,520\n",
      "        Identity-142            [1, 6, 197, 64]               0\n",
      "        Identity-143            [1, 6, 197, 64]               0\n",
      "          Linear-144              [1, 197, 384]         147,840\n",
      "         Dropout-145              [1, 197, 384]               0\n",
      "       Attention-146              [1, 197, 384]               0\n",
      "        Identity-147              [1, 197, 384]               0\n",
      "        Identity-148              [1, 197, 384]               0\n",
      "       LayerNorm-149              [1, 197, 384]             768\n",
      "          Linear-150             [1, 197, 1536]         591,360\n",
      "            GELU-151             [1, 197, 1536]               0\n",
      "         Dropout-152             [1, 197, 1536]               0\n",
      "          Linear-153              [1, 197, 384]         590,208\n",
      "         Dropout-154              [1, 197, 384]               0\n",
      "             Mlp-155              [1, 197, 384]               0\n",
      "        Identity-156              [1, 197, 384]               0\n",
      "        Identity-157              [1, 197, 384]               0\n",
      "           Block-158              [1, 197, 384]               0\n",
      "       LayerNorm-159              [1, 197, 384]             768\n",
      "          Linear-160             [1, 197, 1152]         443,520\n",
      "        Identity-161            [1, 6, 197, 64]               0\n",
      "        Identity-162            [1, 6, 197, 64]               0\n",
      "          Linear-163              [1, 197, 384]         147,840\n",
      "         Dropout-164              [1, 197, 384]               0\n",
      "       Attention-165              [1, 197, 384]               0\n",
      "        Identity-166              [1, 197, 384]               0\n",
      "        Identity-167              [1, 197, 384]               0\n",
      "       LayerNorm-168              [1, 197, 384]             768\n",
      "          Linear-169             [1, 197, 1536]         591,360\n",
      "            GELU-170             [1, 197, 1536]               0\n",
      "         Dropout-171             [1, 197, 1536]               0\n",
      "          Linear-172              [1, 197, 384]         590,208\n",
      "         Dropout-173              [1, 197, 384]               0\n",
      "             Mlp-174              [1, 197, 384]               0\n",
      "        Identity-175              [1, 197, 384]               0\n",
      "        Identity-176              [1, 197, 384]               0\n",
      "           Block-177              [1, 197, 384]               0\n",
      "       LayerNorm-178              [1, 197, 384]             768\n",
      "          Linear-179             [1, 197, 1152]         443,520\n",
      "        Identity-180            [1, 6, 197, 64]               0\n",
      "        Identity-181            [1, 6, 197, 64]               0\n",
      "          Linear-182              [1, 197, 384]         147,840\n",
      "         Dropout-183              [1, 197, 384]               0\n",
      "       Attention-184              [1, 197, 384]               0\n",
      "        Identity-185              [1, 197, 384]               0\n",
      "        Identity-186              [1, 197, 384]               0\n",
      "       LayerNorm-187              [1, 197, 384]             768\n",
      "          Linear-188             [1, 197, 1536]         591,360\n",
      "            GELU-189             [1, 197, 1536]               0\n",
      "         Dropout-190             [1, 197, 1536]               0\n",
      "          Linear-191              [1, 197, 384]         590,208\n",
      "         Dropout-192              [1, 197, 384]               0\n",
      "             Mlp-193              [1, 197, 384]               0\n",
      "        Identity-194              [1, 197, 384]               0\n",
      "        Identity-195              [1, 197, 384]               0\n",
      "           Block-196              [1, 197, 384]               0\n",
      "       LayerNorm-197              [1, 197, 384]             768\n",
      "          Linear-198             [1, 197, 1152]         443,520\n",
      "        Identity-199            [1, 6, 197, 64]               0\n",
      "        Identity-200            [1, 6, 197, 64]               0\n",
      "          Linear-201              [1, 197, 384]         147,840\n",
      "         Dropout-202              [1, 197, 384]               0\n",
      "       Attention-203              [1, 197, 384]               0\n",
      "        Identity-204              [1, 197, 384]               0\n",
      "        Identity-205              [1, 197, 384]               0\n",
      "       LayerNorm-206              [1, 197, 384]             768\n",
      "          Linear-207             [1, 197, 1536]         591,360\n",
      "            GELU-208             [1, 197, 1536]               0\n",
      "         Dropout-209             [1, 197, 1536]               0\n",
      "          Linear-210              [1, 197, 384]         590,208\n",
      "         Dropout-211              [1, 197, 384]               0\n",
      "             Mlp-212              [1, 197, 384]               0\n",
      "        Identity-213              [1, 197, 384]               0\n",
      "        Identity-214              [1, 197, 384]               0\n",
      "           Block-215              [1, 197, 384]               0\n",
      "       LayerNorm-216              [1, 197, 384]             768\n",
      "          Linear-217             [1, 197, 1152]         443,520\n",
      "        Identity-218            [1, 6, 197, 64]               0\n",
      "        Identity-219            [1, 6, 197, 64]               0\n",
      "          Linear-220              [1, 197, 384]         147,840\n",
      "         Dropout-221              [1, 197, 384]               0\n",
      "       Attention-222              [1, 197, 384]               0\n",
      "        Identity-223              [1, 197, 384]               0\n",
      "        Identity-224              [1, 197, 384]               0\n",
      "       LayerNorm-225              [1, 197, 384]             768\n",
      "          Linear-226             [1, 197, 1536]         591,360\n",
      "            GELU-227             [1, 197, 1536]               0\n",
      "         Dropout-228             [1, 197, 1536]               0\n",
      "          Linear-229              [1, 197, 384]         590,208\n",
      "         Dropout-230              [1, 197, 384]               0\n",
      "             Mlp-231              [1, 197, 384]               0\n",
      "        Identity-232              [1, 197, 384]               0\n",
      "        Identity-233              [1, 197, 384]               0\n",
      "           Block-234              [1, 197, 384]               0\n",
      "       LayerNorm-235              [1, 197, 384]             768\n",
      "        Identity-236                   [1, 384]               0\n",
      "         Dropout-237                   [1, 384]               0\n",
      "          Linear-238                  [1, 1000]         385,000\n",
      "================================================================\n",
      "Total params: 21,974,632\n",
      "Trainable params: 21,974,632\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 211.82\n",
      "Params size (MB): 83.83\n",
      "Estimated Total Size (MB): 296.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "a = timm.models.deit.deit_small_patch16_224(pretrained=True)\n",
    "\n",
    "summary_(a, (3,224,224), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 88.3M/88.3M [00:10<00:00, 8.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [1, 384, 14, 14]         295,296\n",
      "          Identity-2              [1, 196, 384]               0\n",
      "        PatchEmbed-3              [1, 196, 384]               0\n",
      "           Dropout-4              [1, 197, 384]               0\n",
      "          Identity-5              [1, 197, 384]               0\n",
      "          Identity-6              [1, 197, 384]               0\n",
      "         LayerNorm-7              [1, 197, 384]             768\n",
      "            Linear-8             [1, 197, 1152]         443,520\n",
      "          Identity-9            [1, 6, 197, 64]               0\n",
      "         Identity-10            [1, 6, 197, 64]               0\n",
      "           Linear-11              [1, 197, 384]         147,840\n",
      "          Dropout-12              [1, 197, 384]               0\n",
      "        Attention-13              [1, 197, 384]               0\n",
      "       LayerScale-14              [1, 197, 384]               0\n",
      "         Identity-15              [1, 197, 384]               0\n",
      "        LayerNorm-16              [1, 197, 384]             768\n",
      "           Linear-17             [1, 197, 1536]         591,360\n",
      "             GELU-18             [1, 197, 1536]               0\n",
      "          Dropout-19             [1, 197, 1536]               0\n",
      "           Linear-20              [1, 197, 384]         590,208\n",
      "          Dropout-21              [1, 197, 384]               0\n",
      "              Mlp-22              [1, 197, 384]               0\n",
      "       LayerScale-23              [1, 197, 384]               0\n",
      "         Identity-24              [1, 197, 384]               0\n",
      "            Block-25              [1, 197, 384]               0\n",
      "        LayerNorm-26              [1, 197, 384]             768\n",
      "           Linear-27             [1, 197, 1152]         443,520\n",
      "         Identity-28            [1, 6, 197, 64]               0\n",
      "         Identity-29            [1, 6, 197, 64]               0\n",
      "           Linear-30              [1, 197, 384]         147,840\n",
      "          Dropout-31              [1, 197, 384]               0\n",
      "        Attention-32              [1, 197, 384]               0\n",
      "       LayerScale-33              [1, 197, 384]               0\n",
      "         Identity-34              [1, 197, 384]               0\n",
      "        LayerNorm-35              [1, 197, 384]             768\n",
      "           Linear-36             [1, 197, 1536]         591,360\n",
      "             GELU-37             [1, 197, 1536]               0\n",
      "          Dropout-38             [1, 197, 1536]               0\n",
      "           Linear-39              [1, 197, 384]         590,208\n",
      "          Dropout-40              [1, 197, 384]               0\n",
      "              Mlp-41              [1, 197, 384]               0\n",
      "       LayerScale-42              [1, 197, 384]               0\n",
      "         Identity-43              [1, 197, 384]               0\n",
      "            Block-44              [1, 197, 384]               0\n",
      "        LayerNorm-45              [1, 197, 384]             768\n",
      "           Linear-46             [1, 197, 1152]         443,520\n",
      "         Identity-47            [1, 6, 197, 64]               0\n",
      "         Identity-48            [1, 6, 197, 64]               0\n",
      "           Linear-49              [1, 197, 384]         147,840\n",
      "          Dropout-50              [1, 197, 384]               0\n",
      "        Attention-51              [1, 197, 384]               0\n",
      "       LayerScale-52              [1, 197, 384]               0\n",
      "         Identity-53              [1, 197, 384]               0\n",
      "        LayerNorm-54              [1, 197, 384]             768\n",
      "           Linear-55             [1, 197, 1536]         591,360\n",
      "             GELU-56             [1, 197, 1536]               0\n",
      "          Dropout-57             [1, 197, 1536]               0\n",
      "           Linear-58              [1, 197, 384]         590,208\n",
      "          Dropout-59              [1, 197, 384]               0\n",
      "              Mlp-60              [1, 197, 384]               0\n",
      "       LayerScale-61              [1, 197, 384]               0\n",
      "         Identity-62              [1, 197, 384]               0\n",
      "            Block-63              [1, 197, 384]               0\n",
      "        LayerNorm-64              [1, 197, 384]             768\n",
      "           Linear-65             [1, 197, 1152]         443,520\n",
      "         Identity-66            [1, 6, 197, 64]               0\n",
      "         Identity-67            [1, 6, 197, 64]               0\n",
      "           Linear-68              [1, 197, 384]         147,840\n",
      "          Dropout-69              [1, 197, 384]               0\n",
      "        Attention-70              [1, 197, 384]               0\n",
      "       LayerScale-71              [1, 197, 384]               0\n",
      "         Identity-72              [1, 197, 384]               0\n",
      "        LayerNorm-73              [1, 197, 384]             768\n",
      "           Linear-74             [1, 197, 1536]         591,360\n",
      "             GELU-75             [1, 197, 1536]               0\n",
      "          Dropout-76             [1, 197, 1536]               0\n",
      "           Linear-77              [1, 197, 384]         590,208\n",
      "          Dropout-78              [1, 197, 384]               0\n",
      "              Mlp-79              [1, 197, 384]               0\n",
      "       LayerScale-80              [1, 197, 384]               0\n",
      "         Identity-81              [1, 197, 384]               0\n",
      "            Block-82              [1, 197, 384]               0\n",
      "        LayerNorm-83              [1, 197, 384]             768\n",
      "           Linear-84             [1, 197, 1152]         443,520\n",
      "         Identity-85            [1, 6, 197, 64]               0\n",
      "         Identity-86            [1, 6, 197, 64]               0\n",
      "           Linear-87              [1, 197, 384]         147,840\n",
      "          Dropout-88              [1, 197, 384]               0\n",
      "        Attention-89              [1, 197, 384]               0\n",
      "       LayerScale-90              [1, 197, 384]               0\n",
      "         Identity-91              [1, 197, 384]               0\n",
      "        LayerNorm-92              [1, 197, 384]             768\n",
      "           Linear-93             [1, 197, 1536]         591,360\n",
      "             GELU-94             [1, 197, 1536]               0\n",
      "          Dropout-95             [1, 197, 1536]               0\n",
      "           Linear-96              [1, 197, 384]         590,208\n",
      "          Dropout-97              [1, 197, 384]               0\n",
      "              Mlp-98              [1, 197, 384]               0\n",
      "       LayerScale-99              [1, 197, 384]               0\n",
      "        Identity-100              [1, 197, 384]               0\n",
      "           Block-101              [1, 197, 384]               0\n",
      "       LayerNorm-102              [1, 197, 384]             768\n",
      "          Linear-103             [1, 197, 1152]         443,520\n",
      "        Identity-104            [1, 6, 197, 64]               0\n",
      "        Identity-105            [1, 6, 197, 64]               0\n",
      "          Linear-106              [1, 197, 384]         147,840\n",
      "         Dropout-107              [1, 197, 384]               0\n",
      "       Attention-108              [1, 197, 384]               0\n",
      "      LayerScale-109              [1, 197, 384]               0\n",
      "        Identity-110              [1, 197, 384]               0\n",
      "       LayerNorm-111              [1, 197, 384]             768\n",
      "          Linear-112             [1, 197, 1536]         591,360\n",
      "            GELU-113             [1, 197, 1536]               0\n",
      "         Dropout-114             [1, 197, 1536]               0\n",
      "          Linear-115              [1, 197, 384]         590,208\n",
      "         Dropout-116              [1, 197, 384]               0\n",
      "             Mlp-117              [1, 197, 384]               0\n",
      "      LayerScale-118              [1, 197, 384]               0\n",
      "        Identity-119              [1, 197, 384]               0\n",
      "           Block-120              [1, 197, 384]               0\n",
      "       LayerNorm-121              [1, 197, 384]             768\n",
      "          Linear-122             [1, 197, 1152]         443,520\n",
      "        Identity-123            [1, 6, 197, 64]               0\n",
      "        Identity-124            [1, 6, 197, 64]               0\n",
      "          Linear-125              [1, 197, 384]         147,840\n",
      "         Dropout-126              [1, 197, 384]               0\n",
      "       Attention-127              [1, 197, 384]               0\n",
      "      LayerScale-128              [1, 197, 384]               0\n",
      "        Identity-129              [1, 197, 384]               0\n",
      "       LayerNorm-130              [1, 197, 384]             768\n",
      "          Linear-131             [1, 197, 1536]         591,360\n",
      "            GELU-132             [1, 197, 1536]               0\n",
      "         Dropout-133             [1, 197, 1536]               0\n",
      "          Linear-134              [1, 197, 384]         590,208\n",
      "         Dropout-135              [1, 197, 384]               0\n",
      "             Mlp-136              [1, 197, 384]               0\n",
      "      LayerScale-137              [1, 197, 384]               0\n",
      "        Identity-138              [1, 197, 384]               0\n",
      "           Block-139              [1, 197, 384]               0\n",
      "       LayerNorm-140              [1, 197, 384]             768\n",
      "          Linear-141             [1, 197, 1152]         443,520\n",
      "        Identity-142            [1, 6, 197, 64]               0\n",
      "        Identity-143            [1, 6, 197, 64]               0\n",
      "          Linear-144              [1, 197, 384]         147,840\n",
      "         Dropout-145              [1, 197, 384]               0\n",
      "       Attention-146              [1, 197, 384]               0\n",
      "      LayerScale-147              [1, 197, 384]               0\n",
      "        Identity-148              [1, 197, 384]               0\n",
      "       LayerNorm-149              [1, 197, 384]             768\n",
      "          Linear-150             [1, 197, 1536]         591,360\n",
      "            GELU-151             [1, 197, 1536]               0\n",
      "         Dropout-152             [1, 197, 1536]               0\n",
      "          Linear-153              [1, 197, 384]         590,208\n",
      "         Dropout-154              [1, 197, 384]               0\n",
      "             Mlp-155              [1, 197, 384]               0\n",
      "      LayerScale-156              [1, 197, 384]               0\n",
      "        Identity-157              [1, 197, 384]               0\n",
      "           Block-158              [1, 197, 384]               0\n",
      "       LayerNorm-159              [1, 197, 384]             768\n",
      "          Linear-160             [1, 197, 1152]         443,520\n",
      "        Identity-161            [1, 6, 197, 64]               0\n",
      "        Identity-162            [1, 6, 197, 64]               0\n",
      "          Linear-163              [1, 197, 384]         147,840\n",
      "         Dropout-164              [1, 197, 384]               0\n",
      "       Attention-165              [1, 197, 384]               0\n",
      "      LayerScale-166              [1, 197, 384]               0\n",
      "        Identity-167              [1, 197, 384]               0\n",
      "       LayerNorm-168              [1, 197, 384]             768\n",
      "          Linear-169             [1, 197, 1536]         591,360\n",
      "            GELU-170             [1, 197, 1536]               0\n",
      "         Dropout-171             [1, 197, 1536]               0\n",
      "          Linear-172              [1, 197, 384]         590,208\n",
      "         Dropout-173              [1, 197, 384]               0\n",
      "             Mlp-174              [1, 197, 384]               0\n",
      "      LayerScale-175              [1, 197, 384]               0\n",
      "        Identity-176              [1, 197, 384]               0\n",
      "           Block-177              [1, 197, 384]               0\n",
      "       LayerNorm-178              [1, 197, 384]             768\n",
      "          Linear-179             [1, 197, 1152]         443,520\n",
      "        Identity-180            [1, 6, 197, 64]               0\n",
      "        Identity-181            [1, 6, 197, 64]               0\n",
      "          Linear-182              [1, 197, 384]         147,840\n",
      "         Dropout-183              [1, 197, 384]               0\n",
      "       Attention-184              [1, 197, 384]               0\n",
      "      LayerScale-185              [1, 197, 384]               0\n",
      "        Identity-186              [1, 197, 384]               0\n",
      "       LayerNorm-187              [1, 197, 384]             768\n",
      "          Linear-188             [1, 197, 1536]         591,360\n",
      "            GELU-189             [1, 197, 1536]               0\n",
      "         Dropout-190             [1, 197, 1536]               0\n",
      "          Linear-191              [1, 197, 384]         590,208\n",
      "         Dropout-192              [1, 197, 384]               0\n",
      "             Mlp-193              [1, 197, 384]               0\n",
      "      LayerScale-194              [1, 197, 384]               0\n",
      "        Identity-195              [1, 197, 384]               0\n",
      "           Block-196              [1, 197, 384]               0\n",
      "       LayerNorm-197              [1, 197, 384]             768\n",
      "          Linear-198             [1, 197, 1152]         443,520\n",
      "        Identity-199            [1, 6, 197, 64]               0\n",
      "        Identity-200            [1, 6, 197, 64]               0\n",
      "          Linear-201              [1, 197, 384]         147,840\n",
      "         Dropout-202              [1, 197, 384]               0\n",
      "       Attention-203              [1, 197, 384]               0\n",
      "      LayerScale-204              [1, 197, 384]               0\n",
      "        Identity-205              [1, 197, 384]               0\n",
      "       LayerNorm-206              [1, 197, 384]             768\n",
      "          Linear-207             [1, 197, 1536]         591,360\n",
      "            GELU-208             [1, 197, 1536]               0\n",
      "         Dropout-209             [1, 197, 1536]               0\n",
      "          Linear-210              [1, 197, 384]         590,208\n",
      "         Dropout-211              [1, 197, 384]               0\n",
      "             Mlp-212              [1, 197, 384]               0\n",
      "      LayerScale-213              [1, 197, 384]               0\n",
      "        Identity-214              [1, 197, 384]               0\n",
      "           Block-215              [1, 197, 384]               0\n",
      "       LayerNorm-216              [1, 197, 384]             768\n",
      "          Linear-217             [1, 197, 1152]         443,520\n",
      "        Identity-218            [1, 6, 197, 64]               0\n",
      "        Identity-219            [1, 6, 197, 64]               0\n",
      "          Linear-220              [1, 197, 384]         147,840\n",
      "         Dropout-221              [1, 197, 384]               0\n",
      "       Attention-222              [1, 197, 384]               0\n",
      "      LayerScale-223              [1, 197, 384]               0\n",
      "        Identity-224              [1, 197, 384]               0\n",
      "       LayerNorm-225              [1, 197, 384]             768\n",
      "          Linear-226             [1, 197, 1536]         591,360\n",
      "            GELU-227             [1, 197, 1536]               0\n",
      "         Dropout-228             [1, 197, 1536]               0\n",
      "          Linear-229              [1, 197, 384]         590,208\n",
      "         Dropout-230              [1, 197, 384]               0\n",
      "             Mlp-231              [1, 197, 384]               0\n",
      "      LayerScale-232              [1, 197, 384]               0\n",
      "        Identity-233              [1, 197, 384]               0\n",
      "           Block-234              [1, 197, 384]               0\n",
      "       LayerNorm-235              [1, 197, 384]             768\n",
      "        Identity-236                   [1, 384]               0\n",
      "         Dropout-237                   [1, 384]               0\n",
      "          Linear-238                  [1, 1000]         385,000\n",
      "================================================================\n",
      "Total params: 21,974,632\n",
      "Trainable params: 21,974,632\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 211.82\n",
      "Params size (MB): 83.83\n",
      "Estimated Total Size (MB): 296.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# b = timm.models.deit.deit3_small_patch16_224.fb_in22k_ft_in1k(pretrained=True)\n",
    "b = timm.create_model('deit3_small_patch16_224.fb_in22k_ft_in1k', pretrained=True)\n",
    "summary_(b, (3,224,224), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 346M/346M [01:32<00:00, 3.73MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [1, 768, 14, 14]         590,592\n",
      "          Identity-2              [1, 196, 768]               0\n",
      "        PatchEmbed-3              [1, 196, 768]               0\n",
      "           Dropout-4              [1, 197, 768]               0\n",
      "          Identity-5              [1, 197, 768]               0\n",
      "          Identity-6              [1, 197, 768]               0\n",
      "         LayerNorm-7              [1, 197, 768]           1,536\n",
      "            Linear-8             [1, 197, 2304]       1,771,776\n",
      "          Identity-9           [1, 12, 197, 64]               0\n",
      "         Identity-10           [1, 12, 197, 64]               0\n",
      "           Linear-11              [1, 197, 768]         590,592\n",
      "          Dropout-12              [1, 197, 768]               0\n",
      "        Attention-13              [1, 197, 768]               0\n",
      "         Identity-14              [1, 197, 768]               0\n",
      "         Identity-15              [1, 197, 768]               0\n",
      "        LayerNorm-16              [1, 197, 768]           1,536\n",
      "           Linear-17             [1, 197, 3072]       2,362,368\n",
      "             GELU-18             [1, 197, 3072]               0\n",
      "          Dropout-19             [1, 197, 3072]               0\n",
      "           Linear-20              [1, 197, 768]       2,360,064\n",
      "          Dropout-21              [1, 197, 768]               0\n",
      "              Mlp-22              [1, 197, 768]               0\n",
      "         Identity-23              [1, 197, 768]               0\n",
      "         Identity-24              [1, 197, 768]               0\n",
      "            Block-25              [1, 197, 768]               0\n",
      "        LayerNorm-26              [1, 197, 768]           1,536\n",
      "           Linear-27             [1, 197, 2304]       1,771,776\n",
      "         Identity-28           [1, 12, 197, 64]               0\n",
      "         Identity-29           [1, 12, 197, 64]               0\n",
      "           Linear-30              [1, 197, 768]         590,592\n",
      "          Dropout-31              [1, 197, 768]               0\n",
      "        Attention-32              [1, 197, 768]               0\n",
      "         Identity-33              [1, 197, 768]               0\n",
      "         Identity-34              [1, 197, 768]               0\n",
      "        LayerNorm-35              [1, 197, 768]           1,536\n",
      "           Linear-36             [1, 197, 3072]       2,362,368\n",
      "             GELU-37             [1, 197, 3072]               0\n",
      "          Dropout-38             [1, 197, 3072]               0\n",
      "           Linear-39              [1, 197, 768]       2,360,064\n",
      "          Dropout-40              [1, 197, 768]               0\n",
      "              Mlp-41              [1, 197, 768]               0\n",
      "         Identity-42              [1, 197, 768]               0\n",
      "         Identity-43              [1, 197, 768]               0\n",
      "            Block-44              [1, 197, 768]               0\n",
      "        LayerNorm-45              [1, 197, 768]           1,536\n",
      "           Linear-46             [1, 197, 2304]       1,771,776\n",
      "         Identity-47           [1, 12, 197, 64]               0\n",
      "         Identity-48           [1, 12, 197, 64]               0\n",
      "           Linear-49              [1, 197, 768]         590,592\n",
      "          Dropout-50              [1, 197, 768]               0\n",
      "        Attention-51              [1, 197, 768]               0\n",
      "         Identity-52              [1, 197, 768]               0\n",
      "         Identity-53              [1, 197, 768]               0\n",
      "        LayerNorm-54              [1, 197, 768]           1,536\n",
      "           Linear-55             [1, 197, 3072]       2,362,368\n",
      "             GELU-56             [1, 197, 3072]               0\n",
      "          Dropout-57             [1, 197, 3072]               0\n",
      "           Linear-58              [1, 197, 768]       2,360,064\n",
      "          Dropout-59              [1, 197, 768]               0\n",
      "              Mlp-60              [1, 197, 768]               0\n",
      "         Identity-61              [1, 197, 768]               0\n",
      "         Identity-62              [1, 197, 768]               0\n",
      "            Block-63              [1, 197, 768]               0\n",
      "        LayerNorm-64              [1, 197, 768]           1,536\n",
      "           Linear-65             [1, 197, 2304]       1,771,776\n",
      "         Identity-66           [1, 12, 197, 64]               0\n",
      "         Identity-67           [1, 12, 197, 64]               0\n",
      "           Linear-68              [1, 197, 768]         590,592\n",
      "          Dropout-69              [1, 197, 768]               0\n",
      "        Attention-70              [1, 197, 768]               0\n",
      "         Identity-71              [1, 197, 768]               0\n",
      "         Identity-72              [1, 197, 768]               0\n",
      "        LayerNorm-73              [1, 197, 768]           1,536\n",
      "           Linear-74             [1, 197, 3072]       2,362,368\n",
      "             GELU-75             [1, 197, 3072]               0\n",
      "          Dropout-76             [1, 197, 3072]               0\n",
      "           Linear-77              [1, 197, 768]       2,360,064\n",
      "          Dropout-78              [1, 197, 768]               0\n",
      "              Mlp-79              [1, 197, 768]               0\n",
      "         Identity-80              [1, 197, 768]               0\n",
      "         Identity-81              [1, 197, 768]               0\n",
      "            Block-82              [1, 197, 768]               0\n",
      "        LayerNorm-83              [1, 197, 768]           1,536\n",
      "           Linear-84             [1, 197, 2304]       1,771,776\n",
      "         Identity-85           [1, 12, 197, 64]               0\n",
      "         Identity-86           [1, 12, 197, 64]               0\n",
      "           Linear-87              [1, 197, 768]         590,592\n",
      "          Dropout-88              [1, 197, 768]               0\n",
      "        Attention-89              [1, 197, 768]               0\n",
      "         Identity-90              [1, 197, 768]               0\n",
      "         Identity-91              [1, 197, 768]               0\n",
      "        LayerNorm-92              [1, 197, 768]           1,536\n",
      "           Linear-93             [1, 197, 3072]       2,362,368\n",
      "             GELU-94             [1, 197, 3072]               0\n",
      "          Dropout-95             [1, 197, 3072]               0\n",
      "           Linear-96              [1, 197, 768]       2,360,064\n",
      "          Dropout-97              [1, 197, 768]               0\n",
      "              Mlp-98              [1, 197, 768]               0\n",
      "         Identity-99              [1, 197, 768]               0\n",
      "        Identity-100              [1, 197, 768]               0\n",
      "           Block-101              [1, 197, 768]               0\n",
      "       LayerNorm-102              [1, 197, 768]           1,536\n",
      "          Linear-103             [1, 197, 2304]       1,771,776\n",
      "        Identity-104           [1, 12, 197, 64]               0\n",
      "        Identity-105           [1, 12, 197, 64]               0\n",
      "          Linear-106              [1, 197, 768]         590,592\n",
      "         Dropout-107              [1, 197, 768]               0\n",
      "       Attention-108              [1, 197, 768]               0\n",
      "        Identity-109              [1, 197, 768]               0\n",
      "        Identity-110              [1, 197, 768]               0\n",
      "       LayerNorm-111              [1, 197, 768]           1,536\n",
      "          Linear-112             [1, 197, 3072]       2,362,368\n",
      "            GELU-113             [1, 197, 3072]               0\n",
      "         Dropout-114             [1, 197, 3072]               0\n",
      "          Linear-115              [1, 197, 768]       2,360,064\n",
      "         Dropout-116              [1, 197, 768]               0\n",
      "             Mlp-117              [1, 197, 768]               0\n",
      "        Identity-118              [1, 197, 768]               0\n",
      "        Identity-119              [1, 197, 768]               0\n",
      "           Block-120              [1, 197, 768]               0\n",
      "       LayerNorm-121              [1, 197, 768]           1,536\n",
      "          Linear-122             [1, 197, 2304]       1,771,776\n",
      "        Identity-123           [1, 12, 197, 64]               0\n",
      "        Identity-124           [1, 12, 197, 64]               0\n",
      "          Linear-125              [1, 197, 768]         590,592\n",
      "         Dropout-126              [1, 197, 768]               0\n",
      "       Attention-127              [1, 197, 768]               0\n",
      "        Identity-128              [1, 197, 768]               0\n",
      "        Identity-129              [1, 197, 768]               0\n",
      "       LayerNorm-130              [1, 197, 768]           1,536\n",
      "          Linear-131             [1, 197, 3072]       2,362,368\n",
      "            GELU-132             [1, 197, 3072]               0\n",
      "         Dropout-133             [1, 197, 3072]               0\n",
      "          Linear-134              [1, 197, 768]       2,360,064\n",
      "         Dropout-135              [1, 197, 768]               0\n",
      "             Mlp-136              [1, 197, 768]               0\n",
      "        Identity-137              [1, 197, 768]               0\n",
      "        Identity-138              [1, 197, 768]               0\n",
      "           Block-139              [1, 197, 768]               0\n",
      "       LayerNorm-140              [1, 197, 768]           1,536\n",
      "          Linear-141             [1, 197, 2304]       1,771,776\n",
      "        Identity-142           [1, 12, 197, 64]               0\n",
      "        Identity-143           [1, 12, 197, 64]               0\n",
      "          Linear-144              [1, 197, 768]         590,592\n",
      "         Dropout-145              [1, 197, 768]               0\n",
      "       Attention-146              [1, 197, 768]               0\n",
      "        Identity-147              [1, 197, 768]               0\n",
      "        Identity-148              [1, 197, 768]               0\n",
      "       LayerNorm-149              [1, 197, 768]           1,536\n",
      "          Linear-150             [1, 197, 3072]       2,362,368\n",
      "            GELU-151             [1, 197, 3072]               0\n",
      "         Dropout-152             [1, 197, 3072]               0\n",
      "          Linear-153              [1, 197, 768]       2,360,064\n",
      "         Dropout-154              [1, 197, 768]               0\n",
      "             Mlp-155              [1, 197, 768]               0\n",
      "        Identity-156              [1, 197, 768]               0\n",
      "        Identity-157              [1, 197, 768]               0\n",
      "           Block-158              [1, 197, 768]               0\n",
      "       LayerNorm-159              [1, 197, 768]           1,536\n",
      "          Linear-160             [1, 197, 2304]       1,771,776\n",
      "        Identity-161           [1, 12, 197, 64]               0\n",
      "        Identity-162           [1, 12, 197, 64]               0\n",
      "          Linear-163              [1, 197, 768]         590,592\n",
      "         Dropout-164              [1, 197, 768]               0\n",
      "       Attention-165              [1, 197, 768]               0\n",
      "        Identity-166              [1, 197, 768]               0\n",
      "        Identity-167              [1, 197, 768]               0\n",
      "       LayerNorm-168              [1, 197, 768]           1,536\n",
      "          Linear-169             [1, 197, 3072]       2,362,368\n",
      "            GELU-170             [1, 197, 3072]               0\n",
      "         Dropout-171             [1, 197, 3072]               0\n",
      "          Linear-172              [1, 197, 768]       2,360,064\n",
      "         Dropout-173              [1, 197, 768]               0\n",
      "             Mlp-174              [1, 197, 768]               0\n",
      "        Identity-175              [1, 197, 768]               0\n",
      "        Identity-176              [1, 197, 768]               0\n",
      "           Block-177              [1, 197, 768]               0\n",
      "       LayerNorm-178              [1, 197, 768]           1,536\n",
      "          Linear-179             [1, 197, 2304]       1,771,776\n",
      "        Identity-180           [1, 12, 197, 64]               0\n",
      "        Identity-181           [1, 12, 197, 64]               0\n",
      "          Linear-182              [1, 197, 768]         590,592\n",
      "         Dropout-183              [1, 197, 768]               0\n",
      "       Attention-184              [1, 197, 768]               0\n",
      "        Identity-185              [1, 197, 768]               0\n",
      "        Identity-186              [1, 197, 768]               0\n",
      "       LayerNorm-187              [1, 197, 768]           1,536\n",
      "          Linear-188             [1, 197, 3072]       2,362,368\n",
      "            GELU-189             [1, 197, 3072]               0\n",
      "         Dropout-190             [1, 197, 3072]               0\n",
      "          Linear-191              [1, 197, 768]       2,360,064\n",
      "         Dropout-192              [1, 197, 768]               0\n",
      "             Mlp-193              [1, 197, 768]               0\n",
      "        Identity-194              [1, 197, 768]               0\n",
      "        Identity-195              [1, 197, 768]               0\n",
      "           Block-196              [1, 197, 768]               0\n",
      "       LayerNorm-197              [1, 197, 768]           1,536\n",
      "          Linear-198             [1, 197, 2304]       1,771,776\n",
      "        Identity-199           [1, 12, 197, 64]               0\n",
      "        Identity-200           [1, 12, 197, 64]               0\n",
      "          Linear-201              [1, 197, 768]         590,592\n",
      "         Dropout-202              [1, 197, 768]               0\n",
      "       Attention-203              [1, 197, 768]               0\n",
      "        Identity-204              [1, 197, 768]               0\n",
      "        Identity-205              [1, 197, 768]               0\n",
      "       LayerNorm-206              [1, 197, 768]           1,536\n",
      "          Linear-207             [1, 197, 3072]       2,362,368\n",
      "            GELU-208             [1, 197, 3072]               0\n",
      "         Dropout-209             [1, 197, 3072]               0\n",
      "          Linear-210              [1, 197, 768]       2,360,064\n",
      "         Dropout-211              [1, 197, 768]               0\n",
      "             Mlp-212              [1, 197, 768]               0\n",
      "        Identity-213              [1, 197, 768]               0\n",
      "        Identity-214              [1, 197, 768]               0\n",
      "           Block-215              [1, 197, 768]               0\n",
      "       LayerNorm-216              [1, 197, 768]           1,536\n",
      "          Linear-217             [1, 197, 2304]       1,771,776\n",
      "        Identity-218           [1, 12, 197, 64]               0\n",
      "        Identity-219           [1, 12, 197, 64]               0\n",
      "          Linear-220              [1, 197, 768]         590,592\n",
      "         Dropout-221              [1, 197, 768]               0\n",
      "       Attention-222              [1, 197, 768]               0\n",
      "        Identity-223              [1, 197, 768]               0\n",
      "        Identity-224              [1, 197, 768]               0\n",
      "       LayerNorm-225              [1, 197, 768]           1,536\n",
      "          Linear-226             [1, 197, 3072]       2,362,368\n",
      "            GELU-227             [1, 197, 3072]               0\n",
      "         Dropout-228             [1, 197, 3072]               0\n",
      "          Linear-229              [1, 197, 768]       2,360,064\n",
      "         Dropout-230              [1, 197, 768]               0\n",
      "             Mlp-231              [1, 197, 768]               0\n",
      "        Identity-232              [1, 197, 768]               0\n",
      "        Identity-233              [1, 197, 768]               0\n",
      "           Block-234              [1, 197, 768]               0\n",
      "       LayerNorm-235              [1, 197, 768]           1,536\n",
      "        Identity-236                   [1, 768]               0\n",
      "         Dropout-237                   [1, 768]               0\n",
      "          Linear-238                  [1, 1000]         769,000\n",
      "================================================================\n",
      "Total params: 86,415,592\n",
      "Trainable params: 86,415,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 423.63\n",
      "Params size (MB): 329.65\n",
      "Estimated Total Size (MB): 753.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "c = timm.create_model('vit_base_patch16_224.augreg_in21k_ft_in1k', pretrained=True)\n",
    "summary_(c, (3,224,224), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
